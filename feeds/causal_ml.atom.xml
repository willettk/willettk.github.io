<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Kyle Willett - causal_ml</title><link href="https://willettk.github.io/" rel="alternate"></link><link href="https://willettk.github.io/feeds/causal_ml.atom.xml" rel="self"></link><id>https://willettk.github.io/</id><updated>2024-06-16T00:00:00-07:00</updated><entry><title>Causal ML - Chapter 2</title><link href="https://willettk.github.io/causal-ml-chapter-2.html" rel="alternate"></link><published>2024-06-16T00:00:00-07:00</published><updated>2024-06-16T00:00:00-07:00</updated><author><name>Kyle Willett</name></author><id>tag:willettk.github.io,2024-06-16:/causal-ml-chapter-2.html</id><summary type="html">&lt;h2&gt;Chapter 2: Causal Inference via Randomized Experiments&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://causalml-book.org/assets/chapters/CausalML_chap_2.pdf"&gt;PDF link to Chapter 2&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Notes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Reminding myself about Chapter 1 as a start, since I've been a few days between these. Key points that I think this will build on were the theoretical derivation of the best linear predictor; statistical properties of â€¦&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;h2&gt;Chapter 2: Causal Inference via Randomized Experiments&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://causalml-book.org/assets/chapters/CausalML_chap_2.pdf"&gt;PDF link to Chapter 2&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Notes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Reminding myself about Chapter 1 as a start, since I've been a few days between these. Key points that I think this will build on were the theoretical derivation of the best linear predictor; statistical properties of least squares and how to attribute different parts of variance; adjusting for small &lt;span class="math"&gt;\(p/n\)&lt;/span&gt;; and "partialling out" as a technique for explaining the effect of what happens when a single random variable changes while others are constant.&lt;/li&gt;
&lt;li&gt;Super short summary: if you randomize (plus other assumptions) and split into two samples, the difference in average outcomes between treated and untreated is the ATE. Using treatment covariates can improve the measurement, and causal diagrams are a method for interpreting the context of the effect.&lt;/li&gt;
&lt;li&gt;The necessity of defining "the underlying state of the world" as a mapping &lt;span class="math"&gt;\(\omega \mapsto V[\omega]\)&lt;/span&gt; falls somewhere between unnecessary and mathematically pretentious on first reading. &lt;/li&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;"The inability to simultaneously observe a unit under both treatment and control is the fundamental problem of causal inference". - Holland (1986).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Seems fair.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;key assumptions, which I should know cold:&lt;ul&gt;
&lt;li&gt;consistency (&lt;span class="math"&gt;\(Y \coloneqq Y[treatment]\)&lt;/span&gt;; i.e., no hidden variation in treatment)&lt;/li&gt;
&lt;li&gt;no interference; potential outcomes for any individual unit are not affected by treatment assignment to other units. &lt;ul&gt;
&lt;li&gt;this is one assumption probably is violated at least mildly in fee change analyses; raising fees on one segment could cause price and ad shifting, which changes economic competition and thus the possible response from other merchants.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;consistency + no interference &lt;span class="math"&gt;\(\equiv\)&lt;/span&gt; &lt;strong&gt;stable unit-treatment value assumption&lt;/strong&gt;, or &lt;strong&gt;SUTVA&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;drumming notation into my head. &lt;span class="math"&gt;\(D\)&lt;/span&gt; (and I think most capitalized variables) is a &lt;em&gt;random variable&lt;/em&gt;, which here corresponds to treatment assignment. &lt;span class="math"&gt;\(d\)&lt;/span&gt; is the (potential) treatment state, which has actual assigned values 0,1 for binary treatment. &lt;/li&gt;
&lt;li&gt;the &lt;em&gt;delta method&lt;/em&gt; is introduced and insufficiently explained when trying to present the concept of relative effectiveness. I've heard this referenced in work-related projects before, so it seems fundamental enough that it's worth a deeper dive.&lt;/li&gt;
&lt;li&gt;The example in the &lt;a href="https://colab.research.google.com/github/CausalAIBook/MetricsMLNotebooks/blob/main/CM1/python-rct-vaccines.ipynb#scrollTo=g-wCDeWCkYem"&gt;colab notebook on vaccine efficacy&lt;/a&gt; is useful in that it's an incredibly recent and relevant case study, which is excellent for motivating an accurate measurement. When calculating the CIs, though, the worked out examples aren't sufficent for me to feel confident repeating it. Authors assert "it's Bernoulli, so X then Y" - but they don't fill in the basics of why the former applies and then how that results in either of the applied variances. This is fairly basic stats and maybe this book should assume readers are beyond that point, but it stirs more mild frustration in me instead of comprehension. On the other hand, the handy breakdown of &lt;code&gt;sm.stats.Table2x2&lt;/code&gt; is extremely useful (although it abstracts away all the assumptions that should go into its use). Useful but dangerous! &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Part 2 - pre-treatment covariates and heterogeneity&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A common mistake seems to center around conditioning on post-treatment covariates, rather than pre-treatment only. Pointed out that, for example, if units with missing covariates are dropped from the analysis (a natural urge), this is equivalent to conditioning on a post-treatment variable. This violates the random assigment assumption.&lt;/li&gt;
&lt;li&gt;Basics: average outcome in the untreated state is &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;, and the average outcome in the treated state is &lt;span class="math"&gt;\((\alpha + \beta_1)\)&lt;/span&gt;. So the lift as I usually think of it in causal inference is &lt;span class="math"&gt;\(\alpha/\beta_1\)&lt;/span&gt;, or the relative ATE. &lt;/li&gt;
&lt;li&gt;The colab notebook asserts that there's an important difference between the ATE computed using non-robust standard errors and robust standard errors. I don't understand what they're referring to in the data, nor do I appreciate what they mean by an "efficient" estimator (vs an accurate or biased one, for example). &lt;em&gt;(later find that this means lower standard errors)&lt;/em&gt; I'm generally finding that the explanation and quality of the coding notebooks is markedly worse than in the text. &lt;/li&gt;
&lt;li&gt;possible useful functions in Python:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;from joblib import Parallel, delayed&lt;/code&gt; - fairly basic way to use multiple processors for execution of functions (&lt;a href="https://joblib.readthedocs.io/en/latest/parallel.html"&gt;see documentation example&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;patsy&lt;/code&gt; - package for describing statistical models in Python. Seems a more robust method of the formula-type language used in R. &lt;a href="https://patsy.readthedocs.io/en/latest/overview.html"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;np.linalg.qr&lt;/code&gt; - useful tip for using QR-decomposition of a matrix to remove multicollinear columns.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;the differences between the two causal diagrams (RCT vs "RCT Research Design") seem somewhere between trivial and important but unexplained. I think it's to emphasize that the impact is from 1) the outcome process + 2) treatment assignment.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Miscellanea on Pelican and HTML stuff&lt;/h4&gt;
&lt;p&gt;From the last post, I learned how to slightly modify &lt;code&gt;Makefile&lt;/code&gt; to support end-to-end publishing to both master and content branches on Github, which is handy.&lt;/p&gt;
&lt;p&gt;I also wish/wonder if the authors would accept git commits to the notebooks (mostly) and the text (occasionally). Mild typos and errata always bug me, and this is exactly the sort of text that could easily crowdsource that from interested readers.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="causal_ml"></category><category term="causal"></category><category term="ml"></category><category term="work"></category></entry><entry><title>Causal ML - Intro and Chapter 1</title><link href="https://willettk.github.io/causal-ml-intro-and-chapter-1.html" rel="alternate"></link><published>2024-06-02T00:00:00-07:00</published><updated>2024-06-02T00:00:00-07:00</updated><author><name>Kyle Willett</name></author><id>tag:willettk.github.io,2024-06-02:/causal-ml-intro-and-chapter-1.html</id><summary type="html">&lt;p&gt;I've been slowly reading the online book &lt;a href="https://causalml-book.org/"&gt;CausalML&lt;/a&gt;, whose authors include some of my distant colleagues at Amazon. My goals are to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read the whole book; to try and maintain momentum, I'm shooting for 1 month timeframe. Basically a chapter every other day.&lt;/li&gt;
&lt;li&gt;Run through the associated notebooks in Python â€¦&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;I've been slowly reading the online book &lt;a href="https://causalml-book.org/"&gt;CausalML&lt;/a&gt;, whose authors include some of my distant colleagues at Amazon. My goals are to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read the whole book; to try and maintain momentum, I'm shooting for 1 month timeframe. Basically a chapter every other day.&lt;/li&gt;
&lt;li&gt;Run through the associated notebooks in Python to work with actual data and implementation.&lt;/li&gt;
&lt;li&gt;Run through at least one code examples in R (rather than my staple of Python), to try to improve my ability to work in another language. &lt;/li&gt;
&lt;li&gt;Take notes on the core concepts, and include areas where I think this could be applied to current and future work.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Chapter 1: Predictive Inference with Linear Regression in Moderately High Dimensions&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://causalml-book.org/assets/chapters/CausalML_chap_1.pdf"&gt;PDF link to Chapter 1&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Notes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;It's interesting to think about the implication that the best linear predictor is not found from setting &lt;span class="math"&gt;\(E[(Y - \beta^\prime X)] = 0\)&lt;/span&gt;, but rather &lt;span class="math"&gt;\(E[(Y - \beta^\prime X)X] = 0\)&lt;/span&gt;. This comes from the fact that this minimizes the &lt;strong&gt;mean squared error&lt;/strong&gt; and not the mean absolute error; not sure if the solution for MAE could be defined since it's non-differentiable.&lt;ul&gt;
&lt;li&gt;Simple decomposition of the solution: &lt;span class="math"&gt;\(Y = \beta^\prime X + \varepsilon\)&lt;/span&gt;, where the residual &lt;span class="math"&gt;\(\varepsilon\)&lt;/span&gt; is orthogonal to the covariate vector &lt;span class="math"&gt;\(X\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Authors refer to the "law of iterated expectations", which is an alternative name for the "&lt;a href="https://en.wikipedia.org/wiki/Law_of_total_expectation"&gt;law of total expectation&lt;/a&gt;". The special case of samples is clearer to me for a practical purpose, similar to how one works out total probabilities for a simple Bayesian approach: &lt;span class="math"&gt;\(E[X] = \sum_i E[X|A_i]P[A_i]\)&lt;/span&gt;. Conditional expectation is important since one can use a &lt;strong&gt;linear combination of non-linear transforms&lt;/strong&gt; to solve the best prediction problem.&lt;/li&gt;
&lt;li&gt;Moving to finite samples &amp;mdash; i.e., the real world &amp;mdash; just replaces the theoretical expectation values with empircal averages over the existing sample. Going from &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; to &lt;span class="math"&gt;\(\hat{\beta}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The decomposition is a clean way to think about how the variance is explained. For &lt;span class="math"&gt;\(E[Y^2] = E[(\beta^\prime X)^2] + E[\varepsilon^2]\)&lt;/span&gt;, the latter term is the population mean squared error. So &lt;span class="math"&gt;\(R^2\)&lt;/span&gt; (either for the population or the sample) is literally the ratio of explained variation by the best linear predictor to the total variation, and is bounded between 0 and 1. This is a good approximation for &lt;span class="math"&gt;\((\textrm{number of }\beta) &amp;lt;&amp;lt; (\textrm{number of samples})\)&lt;/span&gt;, or &lt;span class="math"&gt;\(p/n\)&lt;/span&gt; being small. This can be formally adjusted in a regression, and is automatically provided as a fit parameter if using standard packages like &lt;code&gt;statsmodels&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;I understand the math of partialling out, but link to the earlier material needs a reread. Redo the &lt;a href="https://colab.research.google.com/github/CausalAIBook/MetricsMLNotebooks/blob/main/PM1/python-ols-and-lasso-for-wage-gap-inference.ipynb"&gt;wage-gap notebook&lt;/a&gt; for a practical example.&lt;/li&gt;
&lt;li&gt;Also, why is &lt;span class="math"&gt;\(\beta_1\)&lt;/span&gt; not primed but &lt;span class="math"&gt;\(\beta_2^\prime\)&lt;/span&gt; is?&lt;/li&gt;
&lt;li&gt;Despite having been introduced to them about a dozen times, lasso (and ridge) aren't intuitive concepts to me. Maybe this time through I'll find a better way to make them stick (other than the handwaving statement of "it penalizes certain bits of your regression/helps with overfitting"), which is nowhere near an actual understanding.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Miscellanea on Pelican and HTML stuff&lt;/h4&gt;
&lt;p&gt;As an aside, starting to write these posts resulted in realizing that Markdown as rendered in the browser doesn't natively support mathmode/LaTeX in the same way that Jupyter or IDE Markdown renderers do. the plugin &lt;a href="https://github.com/pelican-plugins/render-math"&gt;render-math&lt;/a&gt; worked well for Pelican right out of the box (although the package has \&amp;lt;30 stars on Github as of Jun 2024, so I'm a bit worried about long-term support/interest). Just &lt;code&gt;pip install pelican-render-math&lt;/code&gt; and add the plugin to &lt;code&gt;pelicanconf.py&lt;/code&gt;. It does take the extra second or so for MathJax to render tech, but I'm grateful that this worked quite easily so far.&lt;/p&gt;
&lt;p&gt;I also was reminded that Pelican automatically names the output HTML files according to the title in the metadata; the actual filename is ignored. This slightly annoys me in that it won't be clear on how content maps to output, if I'm trying to compare? Eg, I can have a content file named &lt;code&gt;content/foobar.md&lt;/code&gt;. If that file has the following content:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;Title&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;apples&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;apples&lt;/span&gt;

&lt;span class="n"&gt;Veggies&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;es&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bonus&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;vobis&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;proinde&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;vos&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;postulo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;essum&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;magis&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;kohlrabi&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;welsh&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;onion&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;daikon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;amaranth&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tatsoi&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tomatillo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;melon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;azuki&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bean&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;garlic&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This article will be rendered as &lt;code&gt;output/apples_to_apples.html&lt;/code&gt;, and would change depending on whatever the title is. It seems confusing in that I don't know what to name my article files now for best practice. &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="causal_ml"></category><category term="causal"></category><category term="ml"></category><category term="work"></category></entry></feed>